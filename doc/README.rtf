{\rtf1\ansi\ansicpg1252\cocoartf1038\cocoasubrtf350
{\fonttbl\f0\fnil\fcharset0 Monaco;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue255;\red0\green170\blue0;\red128\green0\blue0;
}
\margl1440\margr1440\vieww28300\viewh17040\viewkind0
\deftab720
\pard\pardeftab720\ql\qnatural

\f0\fs22 \cf0 Read-me for workflow.jobTree, 10/07/2009 Benedict Paten (\ul benedict\ulnone  AT \ul soe\ulnone  DOT \ul ucsc\ulnone  dot \ul edu\ulnone ), revised 09/17/2010.\
\
\ul Job-tree Introduction:\ulnone \
\
Most batch systems (such as LSF, \ul Parasol\ulnone , etc.) do not allow jobs to spawn\
other jobs in a simple way. \
\
The basic pattern provided by job-tree is as follows: \
\
	(1) You have a job running on your cluster which requires further parallelisation. \
	\
	(2) You create a list of jobs to perform this parallelisation. \
	These are the 'child' jobs of your process, we call them collectively the 'children'.\
	\
	(3) You create a 'follow-on' job, to be performed after all the children \
	have successfully completed. This job is responsible for cleaning up\
	the input files created for the children and doing any further processing. \
	CHILDREN SHOULD NOT CLEANUP FILES CREATED BY PARENTS, in case of a batch system \
	failure which requires the child to be re-run (see 'Atomicity' below)\
	\
	(4) You end your current job successfully.\
	\
	(5) The batch system runs the children. These jobs may in turn have children and follow-on jobs.\
	\
	(6) Upon completion of all the children (and children's children and follow-ons, collectively descendants) \
	the follow-on job is run. The follow-on job may create more children.\
\
\
\ul Script-tree:\ulnone \
\
Script-tree provides a simple Python interface to job-tree, and is the preferred way to use job-tree. \
\
Aside from being the interface to job-tree, script-tree was designed to remediate some of the pain of writing wrapper scripts for cluster jobs, \
via the extension of a simple python wrapper class (called a 'Target' to avoid confusion with the more general use of the word 'job') which does much of the work for you.  Using script-tree, you can describe your script as a series of these classes which link together, with all the arguments and options specified in one place. The script then, using the magic of python pickles, generates all the wrappers dynamically and clean them up when done.\
\
This inherited template pattern has the following advantages:\
\
(1) You write (potentially) just one script, not a series of wrappers. It is much easier to understand, maintain, document and explain.\
(2) You write less boiler plate.\
(2) You can organise all the input arguments and options in one place.\
\
The best way to learn how to use script tree is to look at an example. The following is taken from workflow.jobTree.test.sort.scriptTreeTest_Sort.py which provides a complete script for performing a parallel merge sort. \
\
Below is the first 'Target' of this script inherited from the base class 'workflow.jobTree.scriptTree.Target'. Its job is to setup the merge sort.\
\
\pard\pardeftab720\ql\qnatural
\cf2 class\cf0  Setup(Target):\
    \cf3 """Sets up the sort.\cf0 \
\cf3     """\cf0 \
    \cf2 def\cf0  __init__(self, inputFile, N):\
        Target.__init__(self, time=\cf4 1\cf0 , memory=\cf4 1000000\cf0 , cpu=\cf4 1\cf0 )\
        self.inputFile = inputFile\
        self.N = N\
    \
    \cf2 def\cf0  run(self):\
        tempOutputFile = getTempFile(rootDir=self.getGlobalTempDir())\
        self.addChildTarget(Down(self.inputFile, \cf4 0\cf0 , os.path.getsize(self.inputFile), self.N, tempOutputFile))\
        self.setFollowOnTarget(Cleanup(tempOutputFile, self.inputFile))\
\
The constructor (__init__) assigns some variables to the class. When invoking the constructor of the base class (which should be the first thing the target does), you can optionally pass time (in seconds), memory (in bytes) and cpu parameters. The time parameter is your estimate of how long the target will run, and allows the scheduler to be more efficient. The memory and cpu parameters allow you to guarantee resources for a target.\
\
The run method is where the variables assigned by the constructor are used and where in general actual work is done.\
Aside from doing the specific work of the target (in this case creating a temporary file to hold some intermediate output), the run method is also where children and a follow-on job are created, using addChildTarget() and setFollowOnTarget(). A job may have arbitrary numbers of children, but one or zero follow-on jobs. \
\
Targets are also provided with two temporary file directories called localTempDir and globalTempDir, which can be accessed with the methods getLocalTempDir and getGlobalTempDir, respectively. The localTempDir is the path to a temporary directory that is local to the machine on which the target is being executed and that will exist only for the length of the run method. It is useful for storing interim results that are computed during runtime. All files in this directory are guaranteed to be removed once the run method has finished - even if your target crashes. \
\
A job can either be created as a follow-on, or it can be the very first job, or it can be created as a child of another job. Let a job not created as a follow-on be called a 'founder'. Each founder job may have a follow-on job. If it has a follow-on job, this follow-on job may in turn have a follow-on, etc. Thus each founder job defines a chain of follow-ons.  Let a founder job and its maximal sequence of follow-ons be called a 'chain'. Let the last follow-on job in a chain be called the chain's 'closer'. For each chain of targets a temporary directory, globalTempDir, is created immediately prior to calling the founder target's run method, this directory and its contents then persist until the completion of closer target's run method. Thus the globalTempDir is a scratch directory in which temporary results can be stored on disk between target jobs in a chain. Furthermore, files created in this directory can be passed to the children of target jobs in the chain, allowing results to be transmitted from a target job to its children.\
\
\pard\pardeftab720\ql\qnatural
\cf0 \ul \ulc0 Running a script-tree pipeline:\ulnone \
\
Script-tree targets are serialized (written and retrieved from disk) so that they can be executed in parallel on cluster of different machines. Thankfully, this is mostly transparent to the user, except for the fact that targets must be 'pickled' (see python docs), which creates a few constraints upon what can and can not be passed to and stored by a target. \
\
Currently the preferred way to run a pipeline is to create an executable python script.\
An example of this is shown in tests/sorts/scriptTreeTest_Sort.py. \
\
The first line to notice is:\
\pard\pardeftab720\ql\qnatural
\cf2 from\cf0  workflow.jobTree.scriptTree.target \cf2 import\cf0  Target, Stack\
This imports the Target and Stack objects (the stack object is used to run the targets).\
\
Most of the code defines a series of targets (see above). \
The main() method is where the script is setup and run.\
\
The line:\
	parser = OptionParser()\
Creates an options parser using the python module optparse.\
\
The line:\
	Stack.addJobTreeOptions(parser)\
Adds the job-tree options to the parser. Most importantly it adds the command line options "--jobTree [path to job-tree]", which is the location in which the job-tree will be created, and which must be supplied to the script.\
\
The subsequent lines parse the input arguments, notably the line:\
	options, args = parser.parse_args()\
reads in the input parameters.\
\
The line:\
	i = Stack(Setup(options.fileToSort, int(options.N))).startJobTree(options)\
Is where the first target is created (the Setup target shown above), where\
a stack object is created, which is passed the first target as its sole construction argument, and finally where the job-tree is executed from, using the stack's startJobTree(options) function. The 'options' argument will contain a dictionary of command line arguments which are used by job-tree. The return value of this function is equal to the number of failed targets. In this case we choose to throw an exception if there are any remaining.\
\
One final important detail, the lines:\
	\cf2 if\cf0  __name__ == \cf3 '__main__'\cf0 :\
    		\cf2 from\cf0  workflow.jobTree.test.sort.scriptTreeTest_Sort \cf2 import\cf0  *\
reload the objects in the module, such that their module names will be absolute (this is necessary for the serialization that is used). Targets in other classes that are imported do not need to be reloaded in this way.\
\
The script can then be run, for example using the command: \
\
scriptTreeTest_Sort.py --fileToSort foo --jobTree bar/jobTree --batchSystem parasol --logLevel INFO\
\
Which in this case uses parasol and INFO level logging and where foo is the file to sort and bar/jobTree is the location of a directory (which should not already exist) from which the batch will be managed.\
\
The script will return a zero exit value if the job-tree system is successfully able to run to completion, else it will create an exception. The directory 'bar/jobTree', is not automatically deleted and contains a record of the jobs run, which can be enquired about using the jobTreeStatus.py command. \
\
If the script fails because a target failed then the script will return a non-zero exit value and log file information will be reported to std error (these errors can also be retrieved using the jobTreeStatus command). If you wish to retry the job after fixing the error then the batch can be restarted by calling\
\
jobTreeRun --jobTree bar/jobTree --logLevel INFO\
\
Which will attempt to restart the jobs from the previous point of failure.\
\pard\pardeftab720\ql\qnatural

\fs24 \cf0 	\
\pard\pardeftab720\ql\qnatural
\cf0 \ul Atomicity\ulnone :\
	\
	Job-tree and script-tree are designed to be robust, so that individuals jobs (targets) can fail, and be \
	subsequently restarted. It is assumed jobs can fail at any point. Thus until \
	job-tree knows your children have been completed okay you can not assume that \
	your job (if using script-tree, Target) has been completed. To ensure that your pipeline can be restarted after a failure \
	ensure that every job (target):\
	\
	(1) NEVER CLEANSUP/ALTERS ITS OWN INPUT FILES. \
	Instead, parents and follow on jobs may clean up the files of children or prior jobs.\
	\
	(2) Can be re-run from just its input files any number of times. A job should only depend on its\
	input, and it should be possible to run the job as many times as desired, essentially\
	until news of its completion is successfully transmitted to the job tree master process.\
	\
	These two properties are the key to job atomicity. Additionally, you'll find it much easier if a job:\
	\
	(3) Only creates temp files in the two provided temporary file directories. This ensures we don't\
	soil the cluster's disks.\
	\
	(4) Logs sensibly, so that error messages can be transmitted back to the master and the pipeline can be successfully\
	debugged.\
	\
\ul Environment:\ulnone \
\
	Job-tree replicates the environment in which jobTree or script-tree is invoked and provides this environment to all\
	the jobs/targets. This ensures uniformity of the environment variables for every job.\
\
\ul Probably FAQ's:\ulnone \
\
	Why do we use this pattern?\
	\
		Ideally when issuing children the parent job could just go to sleep on the cluster.\
		But unless it frees the machine it's sleeping on, then the cluster soon jams up\
		with sleeping jobs. This design is a pragmatic way of designing simple parallel code.\
		It isn't heavy duty, it isn't map-reduce, but it has it's niche.\
\
	What do you mean 'crash only' software?\
	\
		This is just a fancy way of saying that job-tree checkpoints its state on  \
		disk, so that it or the job manager can be wiped out and restarted. \
		There is some gnarly test code to show how this works, it will keep crashing everything, at random\
		points, but eventually everything will complete okay.\
		As a consumer you needn't worry about any of this, but your child jobs must \
		be atomic (as with all batch systems), and must follow the convention regarding\
		input files.\
	\
	How scaleable?\
	\
		Probably not very, but it could be. You should be safe to have a 1000 concurrent\
		jobs running, depending on your file-system and batch system.\
		\
	Can you support my XYZ batch system?\
	\
		See the abstract base class 'AbstractBatchSystem' in the code to see what's required.\
		You'll probably need to speak to me as I haven't attempted to comprehensively document these\
		functions, though it's pretty straight forward.\
		\
	Is there an API for the job-tree top level commands?\
	\
		Not really - at this point please use script-tree and the few command line utilities \
		present in the bin directory.
\fs22 \
\
}